# visual_odometry

This software is built for learning visual odometry.

# Reference
- [Visual_Odometry_Tutorial](http://rpg.ifi.uzh.ch/docs/Visual_Odometry_Tutorial.pdf)
- [vo part I and part II](http://rpg.ifi.uzh.ch/visual_odometry_tutorial.html)

# 1 Introduction
## VO Four Assumptions
- ç¯å¢ƒå…‰ç…§è¶³å¤Ÿè¿ç»­
- è¶³å¤Ÿå¤šçš„çº¹ç†ä¿è¯èƒ½å¤Ÿæå–åˆ°æ˜æ˜¾çš„è¿åŠ¨
- Dominance of static scene over moving objectsï¼ˆé™æ€åœºæ™¯æ¯”ç§»åŠ¨ç‰©ä½“æ›´å®¹æ˜“æå–ï¼Ÿï¼‰
- è¿ç»­å¸§ä¹‹é—´æœ‰è¶³å¤Ÿçš„åœºæ™¯é‡å ï¼ˆå˜åŒ–ä¸èƒ½å¤ªå‰§çƒˆï¼Œå¦åˆ™ä¼šæ‰¾ä¸åˆ°ç‰¹å¾ç‚¹ä¹‹é—´çš„åŒ¹é…ï¼Ÿï¼‰

## Why VO?
- ç›¸æ¯”äºè½®å¼é‡Œç¨‹è®¡ä¸å—é™ä¸åœ°å½¢å¹¶ä¸”ç²¾åº¦æ›´å¥½ï¼ˆä½ç½®è¯¯å·®0.1% - 2%,çœŸçš„å‡çš„ï¼Ÿæˆ‘éœ€è¦è¯•ä¸€è¯•ï¼‰
- voå¯ä½œä¸ºä¸€ä¸ªè¡¥å……
  - wheel odometry
  - GPS
  - IMU
  - laser odometry
- åœ¨æ— GPSåŒºåŸŸå†…ä½œç”¨å¾ˆå¤§ï¼Œæ¯”å¦‚æ°´ä¸‹ï¼Œaerialï¼ˆç©ºä¸­ï¼Ÿä»€ä¹ˆé¬¼ï¼Ÿï¼‰

## Working Principle
é€šè¿‡åŒ¹é…è¿ç»­ä¸¤å¸§å›¾åƒçš„ç‰¹å¾ç‚¹ï¼Œæ¥æ¢å¤ç›¸æœºçš„è¿åŠ¨ï¼Œæ±‚å‡ºRï¼Œt

å…·ä½“æ€ä¹ˆæ±‚è§£ï¼Ÿ

## VO Flow Chart
- image sequence
- feature detection
- feature matching
- motion estimationï¼ˆR,tï¼‰
  - 2d-2d(ä¸‰è§’æµ‹é‡)
  - 3d-3d(icp)
  - 3d-2d(pnp)
- local optimization

## VO Drift
è¿åŠ¨è¯¯å·®æ˜¯ç´¯è®¡çš„

## VO or Structure From Motionï¼ˆSFMï¼‰
- SFMæ¯”VOæ›´generalï¼Œç”¨äºè§£å†³ä¸‰ç»´é‡å»ºé—®é¢˜ï¼ŒåŒ…æ‹¬ä»undered image setsä¸­æ¢å¤å‡ºstructureå’Œcamera poses. SFMæœ€ç»ˆçš„structureå’Œcamera poseså¯ä»¥ä½¿ç”¨offline optimizaitonï¼ˆæ¯”å¦‚BAä¼˜åŒ–ï¼‰ï¼Œè®¡ç®—æ—¶é—´éšç€å›¾åƒæ•°é‡çš„å¢é•¿å˜å¤§
- VOæ˜¯SFMçš„particular caseï¼Œæ³¨é‡äºä¼°è®¡3d motion of camera sequentially and in real time. BAï¼ˆoptionalï¼‰å¯ä»¥ç”¨æ¥ä¼˜åŒ–è½¨è¿¹çš„å±€éƒ¨ä¼°è®¡

## VO and Visual SLAM
- SLAMçš„ç›®æ ‡æ˜¯è·å¾—ä¸€ä¸ªglobalï¼Œ consistentçš„æœºå™¨äººè·¯å¾„ä¼°è®¡ï¼Œ è¿™å¯ä»¥é€šè¿‡loop closureså®Œæˆã€‚æ£€æµ‹åˆ°loop closure æ—¶ï¼Œ å¯ä»¥åˆ©ç”¨å›ç¯ä¿¡æ¯é™ä½åœ°å›¾å’Œç›¸æœºè·¯å¾„çš„æ¼‚ç§»ï¼ˆglobal BAï¼‰
- VOè‡´åŠ›äºrecovering the path incrementally, pose after pose, and optimize only over the last m poses path(windowed BA)ã€‚ VOä»…é’ˆå¯¹è½¨è¿¹çš„å±€éƒ¨ä¸€è‡´æ€§ã€‚
- VO å¯ä»¥ç”¨æ¥ä½œä¸ºbuilding block of SLAM. VO is SLAM before closing the loop. VOå°†å®æ—¶æ€§èƒ½çš„ä¸€è‡´æ€§è¿›è¡ŒæŠ˜è¡·ï¼Œè€Œæ— éœ€è·Ÿè¸ªç›¸æœºçš„æ‰€æœ‰å†å²è®°å½•

# 2 Brief history of VO
2004å¹´VOç”¨åœ¨äº†NASAçš„Mars missionçš„æœºå™¨äººä¸­
åŒå¹´ï¼ŒNisterÂ«Visual OdometryÂ»è®ºæ–‡åœ¨å­¦æœ¯ç¯å¢ƒä¸­revived VOï¼Œ VO æµä¼ å¼€æ¥ã€‚

# 3 Problem formulation
è®¾æƒ³ä¸€ä¸ªrobotåœ¨æŸä¸ªç¯å¢ƒä¸‹è¿åŠ¨ï¼Œå®ƒçš„camera systemå’Œæœºå™¨äººæœ¬ä½“åˆšæ€§å›ºå®šï¼ˆrigidly-attachedï¼‰ï¼Œåœ¨ç¦»æ•£æ—¶é—´ä¸‹æ‹æ‘„ä¸€ç³»åˆ—å›¾ç‰‡ã€‚
ç›¸é‚»ä¸¤å¸§ä¹‹é—´çš„å˜æ¢ç”¨Rï¼Œtè¡¨ç¤ºï¼Œè¿™æ ·å¯ä»¥æ±‚å‡ºä»åˆå§‹æ—¶åˆ»åˆ°ç°åœ¨çš„ä¸€ç³»åˆ—å˜æ¢çŸ©é˜µsetï¼Œæœ€åæ±‚å‡ºä¸€ç³»åˆ—camera posesï¼Œéœ€è¦ç”¨åˆ°åˆå§‹æ—¶åˆ»çš„ç›¸æœºåæ ‡ç³»ä½ç½®ã€‚
é€šè¿‡ä¸€ä¸ªm-pose windowed BAæ¥refine cameraè½¨è¿¹ã€‚

# 4 Camera modeling and calibration
- Pin-Hole Approximation
- Omnidirectional Camera Modelï¼ˆå…¨æ™¯ç›¸æœºï¼‰
å¯ä»¥é€šè¿‡Spherical Modelæ¥ç­‰ä»·Perspective å’Œ Omnidirectional Model
å…¨æ™¯ç›¸æœºçš„modelè¿˜ä¸æ¸…æ¥šï¼Ÿ

# 5 Motion estimation
Motion estimationæ˜¯VO systemçš„æ ¸å¿ƒè®¡ç®—æ­¥éª¤ï¼Œè®¡ç®—previous image å’Œcurrent imageä¹‹é—´çš„Rï¼Œtï¼ˆalso called Tï¼‰ï¼Œé€šè¿‡æŠŠè¿™ä¸ªsingle movements è¿æ¥èµ·æ¥ï¼Œrecoverå‡ºfull trajectory of camera.

## æœ‰ä¸¤ç§æ–¹æ³•è®¡ç®—T
- Apperance-based
 ä½¿ç”¨intensityä¿¡æ¯ï¼Œè®¡ç®—more expensive
- Featured-based
 ä½¿ç”¨featureä¿¡æ¯ï¼Œéœ€è¦matchï¼Œmore effective

## å…·ä½“æ±‚è§£Tæœ‰ä¸‰ç§æƒ…å†µ
- 2d-2d(ä¸‰è§’æµ‹é‡ï¼Œepipolar geometry, conputing Essential Matrix)
  The minimal-case solution involves 5-point correspondences.
  relative scale computationï¼Œ ä»ä¸¤å¸§å›¾åƒæ˜¯æ— æ³•è®¡ç®—ç»å¯¹å°ºåº¦çš„ï¼Œä½†æ˜¯å¯ä»¥è®¡ç®—ç›¸å¯¹å°ºåº¦ã€‚ä¸ºäº†robustnessï¼Œscale ratiosé€šå¸¸ç”±å¤šå¯¹å›¾åƒè®¡ç®—å®Œåå–å‡å€¼ã€‚
  both for monocular and stereo
- 3d-3d(icp)
  it is necessary to triangulate 3D points. 
  only for stereo
- 3d-2d(pnp)
  both for monocular and stereo.
  In the monocular case, the 3D structure needs to be triangulated from two adjacent camera views (e.g., ğ¼ğ‘˜âˆ’2 and ğ¼ğ‘˜âˆ’1) and then matched to 2D image features in a third view (e.g., ğ¼ğ‘˜).

## Triangulation and Keyframe Selection
Triangulated 3D points are determined by intersecting backprojected rays from 2D image correspondences of at least two image frames.
å•¥æ„æ€ï¼Ÿï¼Ÿï¼ˆé€šè¿‡äº¤å‰æ¥è‡ªè‡³å°‘ä¸¤ä¸ªå›¾åƒå¸§çš„2Då›¾åƒå¯¹åº”çš„åæŠ•å½±å…‰çº¿æ¥ç¡®å®šä¸‰è§’åŒ–3Dç‚¹ï¼‰

In reality, they never intersectï¼ˆç›¸äº¤ï¼‰ due to
- image noise,
- camera model and calibration errors,
- and feature matching uncertainty

The point at minimal distance from all intersecting rays can be taken as an estimate of the 3D point position.
(è·ç¦»æ‰€æœ‰ç›¸äº¤å…‰çº¿çš„æœ€å°è·ç¦»å¤„çš„ç‚¹å¯ä»¥è¢«è§†ä¸º3Dç‚¹ä½ç½®çš„ä¼°è®¡)

When frames are taken at nearby positions compared to the scene distance, 3D points will exibit large uncertainty

**Therefore, 3D-3D motion estimation methods will drift much more quickly than 3D-2D and 2D-2D methods**

In fact, the uncertainty introduced by triangulation affects the motion estimation. In fact, in the 3D-to-3D case the 3D position error is minimized, while in the 3D-to-2D and 2D-to-2D cases is the image reprojection error.

One way to avoid this consists of skipping frames until the average uncertainty of the 3D points decreases below a certain threshold. The selected frames are called keyframes.

KeyFrame Selection åœ¨VOä¸­æ˜¯éå¸¸é‡è¦çš„ä¸€æ­¥ï¼Œéœ€è¦åœ¨update motionä¹‹å‰å°±å®Œæˆã€‚

## summary
- åœ¨stereoæƒ…å†µä¸‹ï¼Œ 3d-2dæ–¹æ³•æ¯”3d-3dæ–¹æ³•driftæ›´å°‘
- stereoæ¯”monocularåœ¨absolute scaleä¸Šçš„motionå’Œstructureè®¡ç®—æ›´æœ‰ä¼˜åŠ¿ï¼Œ driftä¹Ÿæ›´å°‘
- å½“åœºæ™¯è·ç¦»æ¯”stereo baselineæ›´å¤§çš„æ—¶å€™ï¼Œstereo degenerates(é€€åŒ–) into monocular VO
- KeyFrame Seclectionåº”è¯¥å°å¿ƒè°¨æ…ï¼Œå¯ä»¥é™ä½drift
- æ— è®ºé€‰æ‹©ä»€ä¹ˆè®¡ç®—æ–¹æ³•, local BA (over the last m frames) æ€»ä¼šä½¿å¾—è½¨è¿¹ä¼°è®¡æ›´å‡†ç¡®. After BA, ä¼šå‡å¼±è¿åŠ¨ä¼°è®¡æ–¹æ³•çš„å½±å“ (as long as the initialization is close to the solution)


# 6 Robust estimation
åŒ¹é…ç‚¹é‡Œé¢åŒ…å«outliersï¼Œä¹Ÿå°±æ˜¯åŒ…å«é”™è¯¯åŒ¹é…ï¼ŒRobust Estimationçš„å·¥ä½œå°±æ˜¯å‰”é™¤è¿™äº›outliersã€‚
é€ æˆoutliersçš„åŸå› ï¼š

- image noise
- occlusions(é—­å¡ï¼Ÿå•¥æ„æ€ï¼Ÿ)
- blur
- changes in view point and illumination, feature detector å’Œdescriptorçš„æ•°å­¦æ¨¡å‹æ²¡æœ‰è€ƒè™‘è¿™äº›å˜åŒ–

## RANSAC Example: Line Extraction Algorithm Steps
- select sample of 2 points at random
- calculate model params that fit the data in the sample
- calculate error function for every point left in the sample
- select data that support current hypothesis, store the inliers number
- repeat sampling and do the same thing, until we find a large enough inliners number or iterations numberï¼ˆeg: 1000ï¼‰ is enough, then keep the corresponding selected data that fits hypothesis.
- finally, use the inliers last step to estimate the real model

Fishler & Bollers 1981å·²ç»å»ºç«‹äº†å­˜åœ¨outliersçš„è¿åŠ¨ä¼°è®¡æ ‡å‡†æ–¹æ³•.

éœ€è¦è¿›è¡Œçš„è¿­ä»£æ¬¡æ•°æœ‰å¦‚ä¸‹å…¬å¼è®¡ç®—ï¼š
ï¼® = log(1-p)/log(1-(1-epsilon)^s)

- s: å®ä¾‹åŒ–æ¨¡å‹éœ€è¦çš„ç‚¹çš„æ•°é‡ï¼ˆeg: æ¯”å¦‚ä¼°è®¡ï¼–dofç›¸æœºè¿åŠ¨å¯ä»¥ç”¨5-points RANSACï¼Œå¤§æ¦‚éœ€è¦è¿­ä»£1000æ¬¡, é€šå¸¸éœ€è¦çš„points num = dof - 1ï¼‰
- epsilon: outlierså æ•°æ®æ€»é‡çš„ç™¾åˆ†æ¯”
- p: è¦æ±‚è®¡ç®—æˆåŠŸçš„å‡†ç¡®ç‡
- N: éœ€è¦è¿­ä»£çš„æ¬¡æ•°

RANSACæ¯æ¬¡ç®—å‡ºçš„ç»“æœéƒ½æœ‰ä¸åŒï¼Œä½†æ˜¯å¯¹ç€è¿­ä»£æ¬¡æ•°çš„å¢å¤šä¼šå˜å¾—ç¨³å®šï¼Œä¸ºäº†é²æ£’æ€§ï¼Œé€šå¸¸è¿­ä»£æ¬¡æ•°ä¼šç”¨ä¸Šè¿°å…¬å¼å†ä¹˜ä»¥10å€ã€‚
æ›´é«˜çº§çš„ç®—æ³•å®ç°æœ‰RANSAC estimate the fraction of inliers adaptively.

## å¦‚ä½•é™ä½å®ä¾‹åŒ–æ¨¡å‹éœ€è¦çš„ç‚¹çš„æ•°é‡å‘¢ï¼Ÿ
å¯ä»¥é€šè¿‡è¿åŠ¨çº¦æŸã€‚
æ¯”å¦‚åœ¨äºŒç»´å¹³é¢ï¼Œåªéœ€è¦ä¼°è®¡ï¼“ä¸ªå‚æ•°ï¼Œä¹Ÿå°±æ˜¯éœ€è¦2-points,å¤§æ¦‚éœ€è¦è¿­ä»£100æ¬¡

## exploit the vehicle non-holonomic constraints
æ¯”å¦‚åœ¨äºŒç»´å¹³é¢ï¼Œåˆ©ç”¨Ackermanè½¬å‘åŸç†ï¼Œè½¦å­è½¬å‘å¯ä»¥åªç”¨ï¼’ä¸ªå‚æ•°æè¿°ï¼ˆ1-point neededï¼‰

## is it really better to use minimal sets in RANSAC?
- å¦‚æœå¯¹ç®—æ³•é€Ÿåº¦æœ‰è¦æ±‚ï¼Œé‚£ä¹ˆå°½é‡ä½¿ç”¨minimal sets
- å¦‚æœå›¾åƒå™ªå£°å¾ˆå¤§ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚æ²¡é‚£ä¹ˆè‹›åˆ»ï¼Œä½¿ç”¨non-minimal setä¼šæ›´å¥½

# 7 Error propagation

# 8 Camera-pose optimization (bundle adjustment)
# 9 Discussion
